---
layout: new-section
routeAlias: 'optimisation-performance'
---

<a name="optimisation-performance" id="optimisation-performance"></a>

# Optimisation et Performance ðŸš€

Rendre PostgreSQL ultra-rapide

---

# Plan du module ðŸ“‹

- EXPLAIN et ANALYZE
- Index appropriÃ©s
- Statistiques et VACUUM
- Configuration PostgreSQL
- RequÃªtes optimisÃ©es
- Partitionnement
- Connection pooling

---

# EXPLAIN : Analyser les requÃªtes ðŸ“Š

**EXPLAIN = Le GPS de vos requÃªtes SQL ! ðŸ—ºï¸**

*Analogie* : Votre requÃªte est LENTE ? EXPLAIN vous dit POURQUOI !

C'est comme Google Maps qui vous montre :
- Le chemin que vous allez prendre
- Combien de temps Ã§a va prendre
- S'il y a des bouchons

**Les 2 commandes essentielles** :

**EXPLAIN** = La prÃ©vision ðŸ”®
```sql
EXPLAIN SELECT * FROM produits WHERE prix > 100;
```
ðŸ’¡ PostgreSQL dit : "Voici ce que JE PRÃ‰VOIS de faire"

**EXPLAIN ANALYZE** = La rÃ©alitÃ© âœ…
```sql
EXPLAIN ANALYZE SELECT * FROM produits WHERE prix > 100;
```
ðŸ’¡ PostgreSQL dit : "Voici ce que j'AI VRAIMENT fait + le temps rÃ©el"

---

**Ce que vous verrez** ðŸ‘€ :
```
Seq Scan on produits  (cost=0.00..431.00 rows=100 width=32)
  Filter: (prix > 100)
```

ðŸŒ **Seq Scan** = Il lit TOUTE la table ligne par ligne (LENT !)
- Comme chercher un mot dans un livre en lisant page par page

```
Index Scan using idx_prix on produits  (cost=0.42..8.44 rows=100)
  Index Cond: (prix > 100)
```

âš¡ **Index Scan** = Il utilise un index (RAPIDE !)
- Comme utiliser l'index d'un livre pour aller direct Ã  la bonne page

ðŸ’¡ **RÃ¨gle d'or** : TOUJOURS utiliser EXPLAIN ANALYZE si votre requÃªte est lente !

---

# Lire EXPLAIN ðŸ‘€

```
Seq Scan on produits  (cost=0.00..431.00 rows=100 width=32)
  Filter: (prix > 100)
  
Index Scan using idx_prix on produits  (cost=0.42..8.44 rows=100 width=32)
  Index Cond: (prix > 100)
```

**cost** : Estimation du coÃ»t  
**rows** : Nombre de lignes estimÃ©  
**width** : Taille moyenne d'une ligne

---

# Types de scan ðŸ”

```sql
-- Sequential Scan : Balaye toute la table
Seq Scan on produits

-- Index Scan : Utilise un index
Index Scan using idx_produits_prix

-- Index Only Scan : Tout dans l'index
Index Only Scan using idx_covering

-- Bitmap Index Scan : Combine plusieurs index
Bitmap Index Scan on idx1, idx2
```

---

# Statistiques avec ANALYZE ðŸ“ˆ

```sql
-- Mettre Ã  jour les statistiques
ANALYZE produits;

-- Toutes les tables
ANALYZE;

-- Verbose
ANALYZE VERBOSE produits;

-- Automatique avec autovacuum (dÃ©faut)
```

---

# VACUUM : Nettoyage ðŸ§¹

```sql
-- VACUUM simple : LibÃ¨re l'espace
VACUUM produits;

-- VACUUM FULL : RÃ©organise complÃ¨tement (bloque la table)
VACUUM FULL produits;

-- VACUUM ANALYZE : Nettoie + met Ã  jour stats
VACUUM ANALYZE produits;

-- Automatique : autovacuum (activÃ© par dÃ©faut)
```

---

# Configuration PostgreSQL âš™ï¸

**postgresql.conf - MÃ©moire**

```bash
# MÃ©moire partagÃ©e (25% de la RAM)
shared_buffers = 2GB

# Cache systÃ¨me estimÃ© (75% de la RAM)
effective_cache_size = 6GB

# MÃ©moire par opÃ©ration de tri
work_mem = 50MB

# MÃ©moire maintenance (1-2 GB)
maintenance_work_mem = 1GB
```

---

**Checkpoints et WAL**

```bash
# Taille max WAL avant checkpoint
max_wal_size = 2GB
min_wal_size = 1GB

# Checkpoint timeout
checkpoint_completion_target = 0.9

# WAL buffers
wal_buffers = 16MB
```

---

**ParallÃ©lisme**

```bash
# Nombre de workers parallÃ¨les
max_worker_processes = 8
max_parallel_workers = 8
max_parallel_workers_per_gather = 4

# CoÃ»t pour activer parallÃ©lisme
parallel_tuple_cost = 0.1
parallel_setup_cost = 1000
```

---

**Pour SSD**

```bash
# SSD : accÃ¨s alÃ©atoire rapide
random_page_cost = 1.1  # Au lieu de 4.0

# I/O concurrents
effective_io_concurrency = 200
```

---

# Index stratÃ©giques ðŸ“‘

**Index composites : ordre des colonnes**

```sql
-- Si requÃªte WHERE a = X AND b = Y
CREATE INDEX idx_a_b ON table(a, b);  -- âœ…

-- Si requÃªte WHERE b = Y (seul)
CREATE INDEX idx_b ON table(b);  -- NÃ©cessaire en plus
```

---

**Index partiels**

```sql
-- Indexer uniquement ce qui est utilisÃ©
CREATE INDEX idx_actifs 
ON produits(nom) 
WHERE actif = true;

-- 10x plus petit qu'un index complet !
```

---

**Index covering**

```sql
-- Index contenant toutes les colonnes nÃ©cessaires
CREATE INDEX idx_covering 
ON produits(categorie, prix, nom);

-- RequÃªte servie uniquement par l'index
SELECT nom, prix 
FROM produits 
WHERE categorie = 'Informatique';
-- Index Only Scan !
```

---

# Optimiser les requÃªtes ðŸŽ¯

**Ã‰viter SELECT ***

```sql
-- âŒ MAUVAIS
SELECT * FROM produits WHERE id = 10;

-- âœ… BON
SELECT id, nom, prix FROM produits WHERE id = 10;
```

---

**LIMIT pour pagination**

```sql
-- Pagination efficace
SELECT * FROM articles
ORDER BY date_publication DESC
LIMIT 20 OFFSET 40;

-- Ou avec clÃ©
SELECT * FROM articles
WHERE id > last_seen_id
ORDER BY id
LIMIT 20;
```

---

**EXISTS vs IN**

```sql
-- âœ… MIEUX : EXISTS
SELECT * FROM clients c
WHERE EXISTS (
    SELECT 1 FROM commandes cmd 
    WHERE cmd.client_id = c.id
);

-- âŒ MOINS BON : IN (si beaucoup de rÃ©sultats)
SELECT * FROM clients
WHERE id IN (SELECT client_id FROM commandes);
```

---

**Ã‰viter les fonctions sur colonnes indexÃ©es**

```sql
-- âŒ MAUVAIS : N'utilise pas l'index
SELECT * FROM utilisateurs
WHERE LOWER(email) = 'alice@example.com';

-- âœ… BON : Index d'expression
CREATE INDEX idx_email_lower ON utilisateurs(LOWER(email));
```

---

# Partitionnement de tables ðŸ“¦

**Pour grandes tables (> 100 GB)**

```sql
-- Partitionnement par plage de dates
CREATE TABLE ventes (
    id BIGSERIAL,
    date_vente DATE NOT NULL,
    montant NUMERIC
) PARTITION BY RANGE (date_vente);

CREATE TABLE ventes_2024_q1 PARTITION OF ventes
    FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');
    
CREATE TABLE ventes_2024_q2 PARTITION OF ventes
    FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');
```

---

**Avantages**

- RequÃªtes plus rapides (scan moins de donnÃ©es)
- Maintenance facile (DROP partition)
- Archivage simplifiÃ©
- Index plus petits

---

# Connection Pooling ðŸ”„

**pgBouncer - Pooler externe**

```ini
# pgbouncer.ini
[databases]
mabase = host=localhost dbname=mabase

[pgbouncer]
listen_addr = *
listen_port = 6432
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
pool_mode = transaction
max_client_conn = 1000
default_pool_size = 25
```

---

**Modes de pooling**

- **session** : Connexion gardÃ©e jusqu'Ã  dÃ©connexion client
- **transaction** : Connexion rendue aprÃ¨s chaque transaction
- **statement** : Connexion rendue aprÃ¨s chaque requÃªte

**transaction** est le plus efficace gÃ©nÃ©ralement

---

# Monitoring et mÃ©triques ðŸ“Š

**RequÃªtes lentes**

```sql
-- pg_stat_statements (extension)
CREATE EXTENSION pg_stat_statements;

-- Top requÃªtes lentes
SELECT 
    query,
    calls,
    mean_exec_time,
    total_exec_time
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;
```

---

**Cache hit ratio**

```sql
-- Doit Ãªtre > 95%
SELECT 
    sum(heap_blks_read) as heap_read,
    sum(heap_blks_hit) as heap_hit,
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100 as cache_hit_ratio
FROM pg_statio_user_tables;
```

---

**Index inutilisÃ©s**

```sql
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY pg_relation_size(indexrelid) DESC;
```

---

# Bloat (gonflement) ðŸ’¨

**Identifier le bloat**

```sql
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    n_dead_tup,
    n_live_tup,
    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_ratio
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
ORDER BY n_dead_tup DESC;
```

---

**RÃ©soudre le bloat**

```sql
-- VACUUM rÃ©gulier
VACUUM ANALYZE table_name;

-- Si bloat important
VACUUM FULL table_name;  -- Bloque la table !

-- Ou pg_repack (extension)
pg_repack -d mabase -t table_name
```

---

# Bonnes pratiques ðŸ‘

1. **Index appropriÃ©s** mais pas trop
2. **ANALYZE** aprÃ¨s gros changements
3. **VACUUM** rÃ©gulier (autovacuum suffit souvent)
4. **Monitoring** continu avec pg_stat_statements
5. **Partitionnement** pour grandes tables
6. **Connection pooling** pour haute concurrence
7. **SSD** pour meilleures performances
8. **RequÃªtes optimisÃ©es** : SELECT colonnes nÃ©cessaires

---

# RÃ©sumÃ© ðŸ“

âœ… EXPLAIN ANALYZE pour comprendre
âœ… Index stratÃ©giques et partiels
âœ… VACUUM et ANALYZE rÃ©guliers
âœ… Configuration mÃ©moire appropriÃ©e
âœ… Partitionnement si > 100 GB
âœ… Connection pooling avec pgBouncer
âœ… Monitoring avec pg_stat_statements
âœ… Optimiser requÃªtes (EXISTS, LIMIT, colonnes)

---

# Questions ? ðŸ™‹

**Ã€ suivre** : SÃ©curitÃ© et gestion des utilisateurs

